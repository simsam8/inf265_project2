{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d6cc7-c98e-4095-ba6c-6c35ef9c554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1dbf1-ba98-49cc-a591-aefed0e634fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from collections import Counter\n",
    "from code_base.functions import train, train_models, select_best_model, evaluate_performance\n",
    "from code_base.models import ObjectDetect_2x3\n",
    "from code_base.DataAnalysis import DataAnalysis\n",
    "from code_base.object_detection import get_converted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d47d1-a3d1-4b5e-85bc-6e7fba744630",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 265\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844503ea-ed10-4adf-9ab4-22e804973b68",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177116a-a359-4739-af91-40d861fc6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dimensions = (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf41b84-f92d-4117-9ccf-88f5b84f2921",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_train, object_val, object_test = get_converted_data(grid_dimensions=grid_dimensions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af278884-9cd2-41e1-8759-eab05548f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataAnalysis.plot_detection_instances(object_train, (4,4), grid_dimensions=grid_dimensions, \n",
    "                                      title=\"Ground truth bounding boxes and class\", save_to_file=\"imgs/detection/true.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d857787-6730-47e4-9783-cba412b3067b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee7c8ae-9eb0-48fd-9088-ffa8e54cd56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize from training data\n",
    "imgs = torch.stack([img for img, _ in object_train])\n",
    "\n",
    "# Define normalizer\n",
    "normalizer = transforms.Normalize(\n",
    "    imgs.mean(dim=(0, 2, 3)), \n",
    "    imgs.std(dim=(0, 2, 3))\n",
    "    )\n",
    "\n",
    "object_train_norm = [(normalizer(img), label) for img, label in object_train]\n",
    "object_val_norm = [(normalizer(img), label) for img, label in object_val]\n",
    "object_test_norm = [(normalizer(img), label) for img, label in object_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b332e77b-f409-4a8d-8e3a-15f67491ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(object_train_norm, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "val_loader = DataLoader(object_val_norm, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac892c5a-d647-4ea7-94ae-0ad14ca3d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "networks = [ObjectDetect_2x3]\n",
    "\n",
    "hyper_parameters = [\n",
    "    {\"lr\": 0.001, \"weight_decay\": 0.0},#, \"momentum\": 0.0},\n",
    "    # {\"lr\": 0.05, \"weight_decay\": 0.9},\n",
    "    # {\"lr\": 0.05, \"weight_decay\": 0.1},\n",
    "    # {\"lr\": 0.01, \"weight_decay\": 0.01, \"momentum\": 0.0},\n",
    "    # {\"lr\": 0.01, \"weight_decay\": 0.9, \"momentum\": 0.0},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6343c152-c7c2-4311-b575-41a7add727b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_models(\n",
    "    \"detection\",\n",
    "    networks,\n",
    "    hyper_parameters,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    DEVICE,\n",
    "    SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b74fd9-afc7-4020-9507-d7326970b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_model_idx = select_best_model(results[\"models\"], results[\"strict_val\"])\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298535e-966b-468b-aaec-2f6abfaf4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_hyper_params = results[\"hyper_params\"][best_model_idx]\n",
    "bm_train_loss = results[\"loss_train\"][best_model_idx]\n",
    "bm_val_loss = results[\"loss_val\"][best_model_idx]\n",
    "best_model_train_performance = results[\"strict_train\"][best_model_idx]\n",
    "best_model_val_performance = results[\"strict_val\"][best_model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75691da-725c-4781-a1a5-d94eb4826ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "print(\"Selected hyper parameters\")\n",
    "print(bm_hyper_params)\n",
    "\n",
    "# Loss\n",
    "DataAnalysis.plot_performance_over_time(bm_train_loss, bm_val_loss, \"Training and val loss\", y_label=\"Loss\",\n",
    "                                       save_to_file=\"imgs/detection/loss.png\")\n",
    "\n",
    "# Strict accuracy\n",
    "DataAnalysis.plot_performance_over_time(best_model_train_performance, best_model_val_performance, \"Training and validation strict accuracy over epochs\", \n",
    "                                        y_label=\"Strict Accuracy\", save_to_file=\"imgs/detection/strict.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa76da-db80-4386-b390-cfb27fcf0614",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b746511-4304-4004-8eb6-d766a1c1daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(object_test_norm, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "perf, output = evaluate_performance(\"detection\", best_model, test_loader, device=DEVICE)\n",
    "print(f\"--- Test performance ---\")\n",
    "print(f\"Strict accuracy: {perf['strict']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600c158-e26a-42f7-9e07-d09934003783",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataAnalysis.plot_detection_instances(object_test, (4,4), predictions=output, grid_dimensions=grid_dimensions,\n",
    "                                      title=\"Predicted bounding boxes and class\", save_to_file=\"imgs/detection/pred.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
